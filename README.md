# üîê Bruteforce GPG (Pr√°ctica 2)
Programa en Python para averiguar la passphrase de un fichero cifrado con GnuPG (gpg) por fuerza bruta, suponiendo solo letras min√∫sculas (a..z).
Se prioriza el rendimiento mediante paralelismo, batches (--chunk) y reducci√≥n de I/O (p. ej., /dev/shm).
---

## üì¶ Requisitos 
Sistema GNU/Linux con:

- Python 3.8+
- GnuPG (`gpg`) instalado

Instalaci√≥n recomendada:

```bash
sudo apt update
sudo apt install gpg
```   
## üöÄ Uso r√°pido & Explicaci√≥n de los par√°metros
Formato general: 
```bash
python3 bruteforce.py -f <archivo.gpg> --min <n> --max <n> -j <procesos> --chunk <tama√±o>
```
Ejecuci√≥n recomendada (baseline):
```bash
python3 parallel_lower_brutegpg.py   -f archive.pdf.gpg   --min 4 --max 4   -j $(nproc) --chunk 32 --report-interval 60
```
Explicaci√≥n de los par√°metros:
- -f, --file: ruta al fichero .gpg/.pgp objetivo.
- --min / --max: longitudes m√≠nima y m√°xima a probar (p. ej., --min 4 --max 4 para exactamente 4).
- -j, --jobs: n¬∫ de procesos worker. Recomendado: $(nproc) para usar todos los n√∫cleos.
- --chunk: tama√±o del lote de intentos que procesa cada worker antes de pedir m√°s trabajo.
  - Valores peque√±os (p. ej., 16‚Äì32): mejor tiempo de reacci√≥n cuando se encuentra la pass.
  - Valores grandes (p. ej., 64‚Äì128): m√°s intentos/s (menos overhead por invocaci√≥n a gpg).
- --report-interval: segundos entre informes de progreso (intentos/s, etc.).
## Mejoras & Pruebas
### Dockerfile
He preparado un Dockerfile m√≠nimo basado en python:3.12-slim que instala solo lo imprescindible (gnupg, tini y utilidades b√°sicas), configura GnuPG en modo loopback (sin UI) 
y arranca con tini como init para manejar se√±ales y evitar procesos zombis. Un wrapper (/app/run.sh) copia el fichero objetivo a /dev/shm (RAM) para reducir la latencia de E/S y ejecuta el script con exec,
de modo que la parada al encontrar la clave es inmediata. 

En la ejecuci√≥n de la captura limito CPU y memoria del contenedor (--cpus="$(nproc)", --memory=2g, --memory-swap=2g, --memory-reservation=1g) y monto /dev/shm como tmpfs de 1 GiB
En esta situaci√≥n lanz√≥ mi programa con jobs=32 y chunk=32 (equilibrio throughput/latencia), mostrando un ritmo estable de ‚âà100‚Äì108 intentos/s y encontrando la pass 'drgs' en 618.63 s tras ‚âà63.8 k intentos, 
lo que confirma un dise√±o eficiente, reproducible y orientado a rendimiento:

   <img width="803" height="579" alt="imagen" src="https://github.com/user-attachments/assets/d04409a7-6d65-4591-905e-2f1ffae6fec4" />

### Prueba en RAM

   
# ¬øPor qu√© he optado por esta implementaci√≥n?
## Resultados experimentales y an√°lisis

A continuaci√≥n se muestran tres ejecuciones representativas realizadas durante el desarrollo de la pr√°ctica. Las capturas corresponden a:

1. Ejecuci√≥n local (sin contenedor) usando todos los n√∫cleos y `--chunk 32`.
   <img width="819" height="377" alt="imagen" src="https://github.com/user-attachments/assets/ea8a6b08-d3db-4171-b978-b435f49cb4f0" />
2. Ejecuci√≥n dentro de un contenedor Docker con configuraci√≥n para limitar recursos, mismo comando (`--chunk 32`).
   <img width="795" height="446" alt="imagen" src="https://github.com/user-attachments/assets/c23859a3-7fd9-42e3-b759-e15bb3ceeebd" />

3. Ejecuci√≥n leyendo el archivo desde `/dev/shm` y usando `--chunk 128`.
   <img width="640" height="400" alt="imagen" src="https://github.com/user-attachments/assets/e8669f69-a9d9-4ccf-a530-e9523d78dc5b" />
